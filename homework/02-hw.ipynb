{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA 141B Assignment 2\n",
    "\n",
    "Due __October 27, 2023__ by __11:59pm__. Submit your work by uploading it to Gradescope through Canvas.\n",
    "\n",
    "Please rename this file as __\"LastName_FirstName_hw1\"__ and export it as as pdf-file. \n",
    "\n",
    "The objective of this assignment is to solidify your understanding of programming fundamentals: defining functions, conditional statements, loops, and recursion. Subsequent assignments will delve deeper into data science topics.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Provide your solutions in new cells following each exercise description. Create as many new cells as necessary. Use code cells for your Python scripts and Markdown cells for explanatory text or answers to non-coding questions. Answer all textual questions in complete sentences.\n",
    "\n",
    "2. Prioritize code readability. Just as in writing a book, the clarity of each line matters. Adopt the __one-statement-per-line__ rule. If you have a lengthy code statement, consider breaking it into multiple lines for clarity. (Please note: violating the one-statement-per-line rule will result in a one-point deduction for each offending line.)\n",
    "\n",
    "3. To help understand and maintain code, you should always add comments to explain your code. Use the hash symbol (#) to start writing a comment (homework without any comments will automatically receive 0 points).\n",
    "\n",
    "4. Submit your final work as a __.pdf__ file on __Gradescope__. To convert your .ipynb file into one of these formats, navigate to \"File\", select \"Download as\", and then choose either \"PDF via LaTeX\" or \"HTML\". If \"PDF via LaTeX\" does not work for you, export to \"HTML\", and then use Chrome to print the .html file into PDF. Gradescope only accepts PDF files.\n",
    "\n",
    "5. This assignment will be graded on your proficiency in programming. Be sure to demonstrate your abilities and submit your own, correct and readable solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Data handling\n",
    "\n",
    "---\n",
    "\n",
    "**Background**:\n",
    "\n",
    "The demographic makeup of regions can offer crucial insights into various socio-economic factors. For policymakers, understanding age distributions can be particularly useful, as it can provide direction for initiatives ranging from educational policy to elderly care. In this section, we will work with a dataset detailing the age distribution across U.S. counties, broken down into specific age bins.\n",
    "\n",
    "---\n",
    "\n",
    "### Part 1: Analyzing Age Distribution Across U.S. Counties\n",
    "\n",
    "**Data Source**: 'county_age_dist.csv'\n",
    "\n",
    "This dataset provides a breakdown of the age distribution in each county in the U.S., including territories. It's structured with the 'fips' column indicating the Federal Information Processing Standards code for each county. The age data is categorized into specific age bins (e.g., '0-17', '18-24', and so on).\n",
    "\n",
    "In Part 1, we analyze the age distribution across U.S. counties using the 'county_age_dist.csv' dataset. The tasks span from standardizing data to understanding dominant age groups both at the county and national levels.\n",
    "\n",
    "Please print the result for each subproblem.\n",
    "\n",
    "---\n",
    "\n",
    "__Exercise 1.1 (1 point).__ \n",
    "\n",
    "Ensure that the 'fips' column is standardized. Modify this column such that it is always a 5-digit string. If any 'fips' value has only 4 digits, prepend a '0' to it. For instance, Yolo county should be represented as '06113'. Directly call `county_age` to print the dataframe.\n",
    "\n",
    "Hint: zfill\n",
    "\n",
    "__Exercise 1.2 (2 points).__ \n",
    "\n",
    "Determine the total population of each county:\n",
    "\n",
    "1. Generate a new column called 'population' that represents the total count of all age bins for each county.\n",
    "2. For every age bin, create a corresponding column that indicates its proportion relative to the county's entire population. For example, the column '0-17_rat' should depict the ratio of individuals aged '0-17' to the total population of the respective county.\n",
    "3. Identify the county with the highest proportion of individuals in the '25-34' age bin. What is its FIPS code?\n",
    "4. Similarly, which county has the smallest proportion of residents aged 85 and above? Note down its FIPS code.\n",
    "\n",
    "__Exercise 1.3 (1 point).__ \n",
    "\n",
    "Compute the overall age distribution for the entire U.S:\n",
    "\n",
    "1. Calculate the aggregated count for each age bin across all counties.\n",
    "2. Determine the proportion of each age bin relative to the entire U.S. population.\n",
    "\n",
    "__Exercise 1.4 (2 points).__ \n",
    "\n",
    "Analyze the most common age group for each county:\n",
    "\n",
    "1. Construct a new column named 'mode_age_bin'. This should capture the age bin with the highest proportion in each county. For example, if the most prevalent age group in a county with FIPS code '01001' is '0-17', the corresponding value in 'mode_age_bin' should be '0-17'.\n",
    "2. After determining the mode age bin for each county, calculate the proportion of these modes for all U.S. counties. For instance, compute the percentage of counties where '0-17' is the most dominant age group.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Problem 1.1\n",
      "\n",
      "\n",
      "# Problem 1.2\n",
      "1 & 2. Population and Proportion Columns Added to Dataframe\n",
      "\n",
      "\n",
      "# Problem 1.3\n",
      "\n",
      "\n",
      "# Problem 1.4\n",
      "Mode Age Bin Column Added to Dataframe\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Problem 1.1\n",
    "# Your code Here\n",
    "# Suppose the dataset is stored in a vector named: county_age\n",
    "\n",
    "print(\"# Problem 1.1\")\n",
    "#print(county_age)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Exercise 1.2\n",
    "# Your code Here\n",
    "\n",
    "print(\"# Problem 1.2\")\n",
    "print(\"1 & 2. Population and Proportion Columns Added to Dataframe\")\n",
    "#print(county_age)\n",
    "#print(f\"3. County with highest proportion of '25-34': {max_25_34_fips}\")\n",
    "#print(f\"4. County with smallest proportion of '85+': {min_85_fips}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Exercise 1.3\n",
    "# Your code Here\n",
    "\n",
    "print(\"# Problem 1.3\")\n",
    "#print(\"U.S. Age Distribution Counts:\\n\", us_age_distribution)\n",
    "#print(\"U.S. Age Distribution Ratios:\\n\", us_age_ratios)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Exercise 1.4\n",
    "# Your code Here\n",
    "\n",
    "print(\"# Problem 1.4\")\n",
    "print(\"Mode Age Bin Column Added to Dataframe\")\n",
    "#print(county_age)\n",
    "#print(\"Mode Age Bins Proportions:\\n\", mode_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Incorporating Additional County Information\n",
    "\n",
    "**Data Source**: 'county_fips_master.csv'\n",
    "\n",
    "In this section, we will enrich our analysis by integrating additional county-level information from the 'county_fips_master.csv' file. This dataset contains mapping of counties to their respective state and other metadata.\n",
    "\n",
    "__Exercise 2.1 (2 points).__ \n",
    "\n",
    "Merge the 'county_fips_master.csv' data with the previously constructed age distribution dataframe. Ensure that each row corresponds to a unique county based on the information from the 'county_fips_master' file. Are there counties with missing demographic data? If yes, determine the number of such counties.\n",
    "\n",
    "__Exercise 2.2 (2 points)__\n",
    "\n",
    "Remove rows with incomplete data. For every state in the cleaned dataset, compute the age distribution proportions similar to the earlier national-level analysis. Identify the state with the highest proportion of individuals in the '18-24' age group. Report the state and the corresponding proportion for this age bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exercise 2.1\n",
      "\n",
      "\n",
      "# Exercise 2.2\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2.1: Merging with age distribution dataframe\n",
    "# Load fips names\n",
    "\n",
    "# reformat fips\n",
    "\n",
    "# Merge dataframes\n",
    "\n",
    "# Your code Here\n",
    "\n",
    "# Display a sample of the merged data\n",
    "print(\"# Exercise 2.1\")\n",
    "#print(county_data.iloc[91:100,:])\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check for missing data\n",
    "# Your code Here\n",
    "\n",
    "\"\"\"\n",
    "print(f\"Number of counties with missing demographic data: {num_missing}\")\n",
    "if num_missing > 0:\n",
    "    print(\"Missing data for counties:\")\n",
    "    print(missing_counties)\n",
    "print(\"\\n\")\n",
    "\"\"\"\n",
    "\n",
    "# Exercise 2.2: Computing state-level age distribution proportions\n",
    "\n",
    "# Remove incomplete data\n",
    "# Your code Here\n",
    "\n",
    "# Compute state-level age distribution proportions\n",
    "# Your code Here\n",
    "\n",
    "# Find the state with the highest proportion of 18-24 age group\n",
    "# Your code Here\n",
    "\n",
    "print(\"# Exercise 2.2\")\n",
    "#print(f\"The state with the highest proportion of '18-24' age group is {max_18_24_state} with a proportion of {max_18_24_value:.3f}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Analyzing COVID-19 Death Data\n",
    "\n",
    "**Data Source**: 'time_series_covid19_deaths_US.csv'\n",
    "\n",
    "In this section, we will work with the COVID-19 death data sourced from Johns Hopkins University, detailing cumulative death counts for each county in the US on different dates.\n",
    "\n",
    "__Exercise 3.1 (2 points).__ \n",
    "\n",
    "We've obtained a dataset that chronicles the COVID-19 death counts in the US. The goal here is to transform this dataset into a 'tidy' format, ensuring clear columns for date, deaths, population, and county FIPS code. \n",
    "\n",
    "Hint: Consider using the `melt` function in pandas for this transformation.\n",
    "\n",
    "__Exercise 3.2 (2 points).__ \n",
    "\n",
    "As of February 25th, 2021, which county, inclusive of its state, has witnessed the most significant proportional impact in terms of deaths relative to its population? Use the population metric provided within the COVID-19 dataset.\n",
    "\n",
    "__Exercise 3.3 (2 points).__ \n",
    "\n",
    "Let's delve deeper and ascertain the incidence proportion, which denotes the number of deaths on a daily basis per 100,000 population for each county. This metric can be stored in a new dataset for further analyses.\n",
    "\n",
    "__Exercise 3.4 (2 points).__ \n",
    "\n",
    "Instead of a daily perspective, it would be insightful to view the data from a weekly standpoint. Calculate the incidence proportion per week (aggregating over seven days) for each county. To determine the week bearing the heaviest toll, identify the one with the highest average incidence proportion across all counties.\n",
    "\n",
    "Hint: Leverage 'Periods' in pandas to work with time intervals effectively.\n",
    "\n",
    "__Exercise 3.5 (2 points).__ \n",
    "\n",
    "For each week in our dataset (approximately 40 weeks), compute the correlation between the senior population's proportion in a county and that week's incidence proportion for the county. Each county serves as an independent sample in this correlation calculation, and the Spearman method should be used. Finally, list down the correlation value for each of these weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exercise 3.1\n",
      "\n",
      "\n",
      "# Exercise 3.2\n",
      "\n",
      "\n",
      "# Exercise 3.3\n",
      "\n",
      "\n",
      "# Exercise 3.4\n",
      "\n",
      "\n",
      "# Exercise 3.5\n",
      "Spearman correlations for each week:\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "# Your codes here\n",
    "\n",
    "# Exercise 3.1: Tidying the dataframe\n",
    "# Your codes here\n",
    "\n",
    "print(f\"# Exercise 3.1\")\n",
    "#print(tidy_df.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Exercise 3.2: Highest death proportion county as of 2/25/21\n",
    "# Your codes here\n",
    "\n",
    "print(f\"# Exercise 3.2\")\n",
    "#print(f\"County with highest death proportion as of 2/25/21:  {max_death_county['Province_State']}\")\n",
    "#print(df_0225.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Exercise 3.3: Daily incidence proportion\n",
    "# Your codes here\n",
    "\n",
    "print(f\"# Exercise 3.3\")\n",
    "#print(tidy_df.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Exercise 3.4: Weekly incidence proportion\n",
    "# Your codes here\n",
    "\n",
    "print(f\"# Exercise 3.4\")\n",
    "#print(f\"Week with highest average incidence proportion: {max_week}\")\n",
    "#print(weekly_df.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Exercise 3.5: Spearman correlation for each week\n",
    "correlations = []\n",
    "# Your codes here\n",
    "\n",
    "print(f\"# Exercise 3.5\")\n",
    "print(\"Spearman correlations for each week:\")\n",
    "for week, corr in correlations:\n",
    "    pass\n",
    "    #print(f\"Week {week}: {corr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursion\n",
    "\n",
    "Consider the sequcence defined by $a_1 = a_2 = \\sqrt{3}$ and for $n>2$, \n",
    "$$\n",
    "a_n = \\frac{a_{n-1} + a_{n-2}}{1 - a_{n-1}  a_{n-2}}.\n",
    "$$\n",
    "Throughout this exercise you may assume that $F_n$ as $n$-th value of the [Fibonacci sequence](https://en.wikipedia.org/wiki/Fibonacci_sequence) is explicitly known. \n",
    "\n",
    "\n",
    "__Ex 4 a)__ Implement a function `recursive_bad` that takes the positive integer argument `n` and returns $a_n$ by recursively calling itself. For any other argument, `None` shall be returned. Introduce a global variable `count` that counts how often `recursive_bad` is called. This variable shall not be a function argument. __(3 points)__\n",
    "\n",
    "Return the `[recursive_bad(i+1) for i in range(10)]`. \n",
    "\n",
    "__Test cases__\n",
    "```\n",
    "> count = 0\n",
    "> recursive_bad(25)\n",
    "1.7320508075574117\n",
    "> count\n",
    "150049\n",
    "> recursive_bad('hello')\n",
    "> recursive_bad(5)\n",
    "-1.732050807568878\n",
    "```\n",
    "\n",
    "__b)__ How often is the function called? Denote $c_n$ as number of function calls for argument `n` and derive an *explicit* expression for $c_n$.  __(2 points)__\n",
    "\n",
    "Return $c_n$, $n\\in\\{1, \\dots, 10\\}$. \n",
    "\n",
    "*Hint: Relate $c_n$ to $F_n$.*\n",
    "\n",
    "\n",
    "__c)__ Implement a function `dynamic` that takes the positive integer argument `n` and returns `a_n`. For any other argument, `None` shall be returned. The function shall append a list, using the implicit definition of $a_n$ above, until it has `n` entries and return the last one. __(3 points)__\n",
    "\n",
    "Return the command `[dynamic(i+1) for i in range(10)]`. Using `import timeit` and `timeit.default_timer` ([docs](https://docs.python.org/3/library/timeit.html?#timeit.default_timer)) report how long it takes on your machine to calculate $a_n$ using `dynamic` versus `recursion_bad`. \n",
    "\n",
    "__d)__ Implement a function `recursion` that invokes a recursive function. `recursion`  shall take the positive integer argument `n` and return `a_n`. For any other argument, `None` shall be returned. Implement the global `count` as in a).  __(3 points)__\n",
    "\n",
    "\n",
    "Return the command `[recursion(i+1) for i in range(25)]`. \n",
    "\n",
    "__Test cases__\n",
    "```\n",
    "> count = 0\n",
    "> recursion(10)\n",
    "> count\n",
    "9\n",
    "```\n",
    "\n",
    "*Hint: Evaluate the recursion on $n$, $a_n$ and $a_{n-1}$ simultaneously.*\n",
    "\n",
    "__e)__ Implement a function `explicit` that explicitly computes $a_n$. The function takes the positive integer argument `n` as well as the Fibonacci sequence `F` (you may assume that `len(F) > n`) with default value and return `a_n`. __(3 points)__\n",
    "\n",
    "\n",
    "You may use `import numpy` and `numpy.tan` as well as `numpy.pi`. Return the command `[explicit(i+1) for i in range(10)]`. \n",
    "\n",
    "*Hint: Recall that for $a, b\\in\\mathbb R\\colon \\tan(a + b) = (\\tan(a) + \\tan(b)) / (1 - \\tan(a) \\tan(b))$.*\n",
    "\n",
    "__Test cases__\n",
    "```\n",
    "> explicit(1)\n",
    "1.7320508075688767\n",
    "> explicit(-1)\n",
    "> explicit(8)\n",
    "1.7320508075688528\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
